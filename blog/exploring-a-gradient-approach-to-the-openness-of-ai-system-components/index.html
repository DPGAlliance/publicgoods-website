<html>

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>  Exploring a Gradient Approach to the Openness of AI System Components &raquo; Digital Public Goods Alliance</title>
	<script>
		var BLOG_URL = 'https://digitalpublicgoods.net';
		var TEMPLATE_URL = '/wp-content/themes/dpga';
		var AJAX_URL = '/wp-admin/admin-ajax.php';
	</script>
	<link rel="icon" type="image/png" href="/wp-content/themes/dpga/favicon.png?v1622233620" />
	<meta name='robots' content='max-image-preview:large' />
<link rel='stylesheet' id='wp-block-library-css'  href='/wp-includes/css/dist/block-library/style.min.css?ver=5.7.10' type='text/css' media='all' />
<link rel='stylesheet' id='dpga-style-css'  href='/wp-content/themes/dpga/style.css?ver=5.7.10' type='text/css' media='all' />
<link rel='stylesheet' id='dpga-fontello-css'  href='/wp-content/themes/dpga/fontello/css/fontello.css?ver=1622233620' type='text/css' media='all' />
<link rel='stylesheet' id='dpga-style-main-css'  href='/wp-content/themes/dpga/css/style.css?ver=1622233620' type='text/css' media='all' />
<link rel="canonical" href="/blog/exploring-a-gradient-approach-to-the-openness-of-ai-system-components/" />
</head>

<body class="post-template-default single single-post postid-2865 single-format-standard">
	<div id="page">
		<header id="header">
			<nav class="navbar navbar-expand-xl navbar-light">
				<div class="container">
					<button class="navbar-toggler" type="button" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
						<span class="navbar-toggler-icon">
						</span>
					</button>
					<a class="navbar-brand" href="https://digitalpublicgoods.net">
						<span><img src="/wp-content/themes/dpga/images/logo.svg" alt="Digital Public Goods Alliance" /></span>
					</a>

					<div class=" navbar-collapse" id="navbarNavDropdown">
						<div class="menu-main-menu-container"><ul id="menu-main-menu" class="menu"><li id="menu-item-51" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-51"><a href="/">Home</a></li>
<li id="menu-item-186" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-186"><a href="/who-we-are/">Who We Are</a>
<ul class="sub-menu">
	<li id="menu-item-1587" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1587"><a href="/governance/">Governance</a></li>
	<li id="menu-item-2252" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2252"><a href="/digital-public-goods-alliance-secretariat/">Secretariat Team</a></li>
</ul>
</li>
<li id="menu-item-210" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-210"><a href="/what-we-do/">What We Do</a>
<ul class="sub-menu">
	<li id="menu-item-1445" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1445"><a href="/roadmap/">Roadmap</a></li>
	<li id="menu-item-1495" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1495"><a href="/digital-public-goods-alliance-strategy-2021-2026/">Digital Public Goods Alliance Strategy 2021-2026</a></li>
	<li id="menu-item-1088" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1088"><a href="/highlighted-digital-public-goods/">Community of Practice Reports</a></li>
</ul>
</li>
<li id="menu-item-1494" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1494"><a href="/digital-public-goods/">Digital Public Goods</a>
<ul class="sub-menu">
	<li id="menu-item-87" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-87"><a href="/registry/">DPG Registry</a></li>
	<li id="menu-item-562" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-562"><a href="/standard/">DPG Standard</a></li>
	<li id="menu-item-2399" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2399"><a href="/digital-public-goods/submission-guide/">Submission Guide</a></li>
	<li id="menu-item-2398" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2398"><a href="/digital-public-goods/faqs/">DPG Application FAQs</a></li>
</ul>
</li>
<li id="menu-item-263" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-263"><a href="/get-involved/">Get Involved</a></li>
<li id="menu-item-390" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-390"><a href="/blog/">Blog</a></li>
</ul></div>						<button class="close"><i class="icon-cancel"></i></button>
					</div>

					<a href="/?s=" class="search-form"><i class="icon-search"></i></a>
				</div>
			</nav>
		</header><main role="main" id="main">
	<div class="content-wrap">
			<header>
		<h1>Exploring a Gradient Approach to the Openness of AI System Components</h1>
					<div class="entry-meta">
				<b>
					<span class="posted-on"><time class="entry-date published updated" datetime="2023-10-27T15:32:30+00:00">October 27, 2023</time></span>				</b>
			</div>
				<img width="1024" height="706" src="https://s3.amazonaws.com/dpg-website/wp-content/uploads/2023/10/27150712/arthur-mazi-xDsaGQJumBY-unsplash.jpg" class="attachment-large size-large wp-post-image" alt="" loading="lazy" />	</header>
	<div class="body-content">
		
<p><em>The Community of Practice on AI systems as digital public goods, co-hosted by the DPGA and UNICEF, has developed and mapped a first approach to distinguish the degrees of openness of an AI system’s components. Doing so can help equip developers with a tool to think through how and when to open AI systems. This work forms the basis for formulating recommendations for the evolution of the <a href="https://digitalpublicgoods.net/standard/" target="_blank" rel="noreferrer noopener">DPG Standard</a> and focuses on AI systems, including, but not limited to, generative AI.</em></p>



<p>UNICEF and the Digital Public Goods Alliance (DPGA) recognise the positive potential of AI, particularly in international development, and are committed to its responsible use in order to benefit society at large. For this reason, they joined forces in the spring of 2023 to convene a Community of Practice (CoP) which brings together experts from diverse sectors and geographies to explore AI systems as digital public goods: open, accessible, and adaptable tools that can be used to help achieve the sustainable development goals safely and inclusively.</p>



<p>In particular, this CoP aims to look at the intersection of responsible and open AI, understanding that while openness in AI has many benefits, including increased transparency, external oversight, equitable adoption, etc., fully open AI systems (i.e., when data, model with weights and architecture, and software are openly licensed(1)) are not always possible or in the best interest of the public good – especially with the advance of highly capable foundation models. Notable risks include the misuse of models by malicious actors without any oversight and control over downstream use and the disablement of model safeguards (2). One example includes the risk of large language models being used to produce mis- and disinformation, potentially undermining democratic institutions and states. However, the idea that highly closed-source foundation models are safer than highly open foundation models is <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=75OBTMu5UEc&amp;t=3612s" target="_blank">contested among researchers</a>. The complexity of defining &#8216;openness&#8217; increases with DPGs. According to the DPG Standard, to qualify as a digital public good, solutions must not only meet baseline requirements but also ensure they do no harm by design (3).</p>



<p>In open-source software, the transparency and adaptability assured by open licenses are often seen as inherently &#8220;good&#8221; since making code available and modifiable drives innovation, trust, and collaboration. <a href="https://digitalpublicgoods.net/AI-CoP-Discussion-Paper.pdf" target="_blank" rel="noreferrer noopener">This is not always considered to be the case for AI</a>. Exploring this necessitates understanding the current ambiguities surrounding the term &#8220;open,&#8221; especially in relation to data extractivism, data colonialism, and the economics of open data. This exploration should also consider AI development needs, like computing power and financial access, as well as sensitive data and data privacy concerns.</p>



<p>These challenges call for a nuanced approach to defining the properties that form open-source AI systems, especially concerning these systems as digital public goods. To do so, two outcomes are needed: </p>



<ol><li>Establishing a framework for a gradient approach to the openness of AI system components, and;</li><li>Outlining the additional guardrails and safety requirements that can help ensure the responsible opening up of AI systems, including documentation requirements and mandatory risk-mitigating practices, which may be included as requirements of the DPG Standard.</li></ol>



<p>These considerations are essential as near-to fully open-sourcing AI systems may increase the ability for community research, auditability, and bringing in diverse perspectives in the development process. Still, they also ultimately limit control over downstream use and risk management.</p>



<p>To solve this issue, the DPGA and UNICEF, in consultation with the CoP, have developed an exploratory framework that introduces a gradient approach to the openness of AI system components. Open-source AI is <a rel="noreferrer noopener" href="https://blog.opensource.org/towards-a-definition-of-open-artificial-intelligence-first-meeting-recap/" target="_blank">not a black-and-white debate</a> between closed-source and proprietary or open-source systems. Therefore, this framework attempts to shed light on the greyscale between these two poles and define a necessary and sufficient minimum of openness of AI system components for a product to be considered a digital public good (4). </p>



<p><strong>A Gradient Approach to Openness</strong><br>This framework focuses on the three main components of an AI system, building on the understanding put forward in the <a href="https://digitalpublicgoods.net/AI-CoP-Discussion-Paper.pdf" target="_blank" rel="noreferrer noopener">CoP’s mid-term discussion paper</a>, including <strong>data, model, and code</strong>. Among these three components, the openness requirements for AI training data are among the most contested issues in the ongoing discussion on <a href="https://blog.opensource.org/towards-a-definition-of-open-artificial-intelligence-first-meeting-recap/" target="_blank" rel="noreferrer noopener">defining open-source AI</a>. The gradient approach framework acknowledges that access to AI training and testing data does not equal access to source code in the open software world &#8211; which means that you cannot recreate the model by purely open-sourcing the training data used. There is more to an AI system. But how much do we depend on the original dataset to exercise the right to modify and use a model and to ensure transparency and explainability of the model outcomes? Understanding the underlying training and testing datasets is still essential to understanding, observing, and using the AI model. With that said, the exact reproduction of an AI model is of limited use, given the amount of resources needed to do so.&nbsp;</p>



<p>Reproduction of an AI model does not equal auditing; rather, what is needed to scrutinize a model and, for instance, conduct safety evaluations is access to trained weights and model architecture, not necessarily training data. However, as pointed out above, understanding the training data is still vital &#8211; yet, access to the full dataset is not necessarily needed to do so. A gradient approach to AI training data helps to navigate different cultural understandings of open data and address <a href="https://www.rnz.co.nz/news/te-manu-korihi/491925/how-will-chatgpt-impact-te-reo-maori-data-sovereignty-experts-weigh-in" target="_blank" rel="noreferrer noopener">data rights issues</a>, amongst other considerations.</p>



<p>In the CoP, a need to determine what “meaningful openness” constitutes was identified. For example, how do we get to a degree of openness that preserves the attributes like transparency, reusability, and extensibility that are central to open source but does not, strictly speaking, comply with the four freedoms of open source to enable us to navigate the ambiguities previously outlined? In addition, there is a need to help ensure AI DPGs are designed and governed in a way that promotes ethical use and does no harm by design. This could, for instance, include extensive red-teaming, establishing <a rel="noreferrer noopener" href="https://dl.acm.org/doi/pdf/10.1145/3531146.3533779" target="_blank">norms and practices</a> for responsible use in a community, publishing a responsible use guide alongside system components (see <a rel="noreferrer noopener" href="https://ai.meta.com/llama/responsible-use-guide/" target="_blank">Meta’s guide for Llama</a>), public reporting requirements in licenses (see the <a rel="noreferrer noopener" href="https://blog.allenai.org/the-ai2-impact-license-a-new-way-to-think-about-ai-licensing-bc90ff26a9ee" target="_blank">AI2Impact License family</a> for an example) and open-sourcing more <a rel="noreferrer noopener" href="https://hai.stanford.edu/news/how-promote-responsible-open-foundation-models" target="_blank">artifacts that accelerate AI safety research</a>. </p>



<p>The gradient approach to the openness of AI system components was informed by Irene Solaiman’s work on a <a href="https://arxiv.org/abs/2302.04844" target="_blank" rel="noreferrer noopener">gradient release model for generative AI</a> and Tim Berners-Lee’s <a href="https://5stardata.info/en/" target="_blank" rel="noreferrer noopener">5-star deployment model for open data</a>. Both works introduce nuance to their respective fields and reject an all-or-nothing approach. It also builds on the research on the <a href="https://opening-up-chatgpt.github.io/" target="_blank" rel="noreferrer noopener">spectrums of openness of text-generating</a> AI models by Andreas Liesenfeld and colleagues.&nbsp;</p>



<p>In this framework, the data component includes training and testing data of an AI model (5). Documentation for this component must include a description of dataset features, including provenance, structure, and processing steps, which need to be captured in a data card or a similar format. The model component includes model weights, hyperparameters, and model architecture. Documentation should come in the form of a model or system card. The code component comprises the training and inference code of the AI system. Standard software documentation would be required as outlined in the DPG Standard. The framework outlines the necessary and sufficient minimum of openness for each of the three components for an AI system to be considered a DPG in its totality.<br><br>For <strong>the data component,</strong> we propose to be the most permissive and define two stages of “aspirational openness” in addition to fully open-source training and testing datasets. Aspirational openness includes:</p>



<ol><li>Synthetic datasets modeled on the original training and testing data or samples of the datasets used for training or hosted access to the entire training and testing datasets and;</li><li>Datasets with a use-restricting license, such as Open RAIL-D and AI2Impact.</li></ol>



<div class="wp-block-columns">
<div class="wp-block-column">
<div class="wp-block-image"><figure class="aligncenter size-large"><img loading="lazy" width="934" height="659" src="https://s3.amazonaws.com/dpg-website/wp-content/uploads/2023/10/27134510/AI-DPGs-gradient-openness3-1.jpg" alt="" class="wp-image-2884"/></figure></div>
</div>
</div>



<p>AI training and testing data should be treated as a mandatory dependency instead of a standalone dataset in this framework.</p>



<p>For <strong>the model component,</strong> we recommend considering either AI models with a full open-source license or models with an (ethical) use-restricting license(6) such as RAIL-M (“ethical openness”). In addition to licensing, we require that a model be made available with its model weights and model architecture in order to be considered a DPG. Ideally, developers should also open-source trained weights, hyperparameters, loss and reward functions, and any other necessary components and knowledge to optimally (cost- and time-efficiently) fine-tune, train, or reproduce a model. This could include training strategies; related models; data processing code; tacit knowledge etc.</p>



<p>We suggest being the least permissive for <strong>the code component</strong> and requiring training and inference code to be fully open-source according to OSI standards.</p>



<p>With this contribution, we hope to add to the debate on defining open-source AI by bringing in nuance, helping developers to think through the opening process of a system and its components, and inspiring a conversation about the benefits of open-sourcing AI systems. Open-source AI should never be assumed to be an end in itself. Rather, we need to focus on the benefits that come with open-sourcing AI systems. We must carefully approach any definition of AI DPGs not to encourage AI systems&#8217; unsafe and irresponsible release, even if done with the best intentions. In addition, we also acknowledge that additional practices exist that may ensure or come close to realising the benefits of open source in more closed source scenarios, such as AI safety bounties and participatory processes to inform model development, use, and governance (7).</p>



<p>The framework is a starting point for further exploration. Some of the questions the CoP will explore in the coming weeks include reviewing standards for data, model, and system cards; exploring other evolving licenses and requirements in addition to OpenRAIL for inclusion; adding more details on each of the three components’ features to go beyond licensing; considering re-naming the category of “ethical openness”; defining additional guardrails for responsible AI development, which can be integrated into the DPG standard; running case studies to test our approach’s feasibility in vetting DPG applications, and discussing how to prevent product owners from intentionally being more restrictive in opening up data with the introduction of the two aspirational openness categories than is necessary.<br><br>We thank all CoP members for their value contributions in developing this framework. As co-hosts of the CoP on AI systems as digital public goods, the DPGA and UNICEF welcome comments on this approach. Please reach out to <a rel="noreferrer noopener" href="mailto:lea@digitalpublicgoods.net" target="_blank">Lea Gimpel</a>, who leads the DPGA Secretariat’s work on AI if you would like to share your thoughts.&nbsp;</p>



<hr class="wp-block-separator is-style-default"/>



<p><span style="color:#626363" class="has-inline-color"><em><strong>Footnotes</strong></em><br>1. With “openly licensed” we refer to licenses that enable users to use, study, share and modify the artifact.<br>2. For a comprehensive take on the benefits and risks of open-sourcing highly capable models see: Elizabeth Seger et. al. “<a href="https://cdn.governance.ai/Open-Sourcing_Highly_Capable_Foundation_Models_2023_GovAI.pdf">Open-sourcing highly capable foundation models</a>” (2023)<br>3. Indicator 9 of the DPG Standard states DPGs must be designed to anticipate, prevent, and do no harm by design.<br>4. &nbsp;With this, we are also mindful of the ongoing discussion facilitated by OSI to define open-source AI. See the first public draft <a href="https://hackmd.io/@opensourceinitiative/opensource-ai-definition-0-2">here</a>.<br>5. &nbsp;Since the framework is meant to cover the breadth of artificial intelligence techniques, including but not limited to machine-learning and supervised learning, this distinction is used only when applicable.<br>6. A comprehensive list of which licenses and allowed restrictions will be considered needs to be developed in the CoP as a next step.<br>7. See Elizabeth Seger et al. “<a href="https://cdn.governance.ai/Open-Sourcing_Highly_Capable_Foundation_Models_2023_GovAI.pdf">Open-sourcing highly capable foundation models</a>” (2023)<br></span></p>
	</div>
			</div>
</main>
</div>
<footer id="footer">
	<div>
		<div class="container">
			<div id="sidebar-footer" class="sidebar">
				<aside id="text-2" class="widget widget_text"><h5 class="widget-title">Connect</h5>			<div class="textwidget"><p><span style="font-weight: 400;"><a href="https://mailchi.mp/4ae88231c358/digital-public-goods-mailing-list">Sign up</a> to receive our monthly newsletter.</span></p>
</div>
		</aside><aside id="text-4" class="widget widget_text"><h5 class="widget-title">Inquiries</h5>			<div class="textwidget"><p>Have a question? <a href="mailto:hello@digitalpublicgoods.net">Contact us here</a>.</p>
</div>
		</aside><aside id="text-3" class="widget widget_text"><h5 class="widget-title">Contribute</h5>			<div class="textwidget"><p>Join us by contributing on <a href="https://github.com/dpgalliance" target="_blank" rel="noopener">GitHub</a>.</p>
</div>
		</aside>			</div>
		</div>
	</div>
	<div>
		<div class="container">
			<div class="site-info">
				<a class="footer-brand" href="https://digitalpublicgoods.net">
					<span><img src="/wp-content/themes/dpga/images/logo-w.svg" alt="Digital Public Goods Alliance" /></span>
				</a>
				<div>
					<div class="menu-footer-menu-container"><ul id="menu-footer-menu" class="menu"><li id="menu-item-1511" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1511"><a href="https://digitalpublicgoods.net/DPGA_Brand-Guide.pdf">DPGA Brand Guide</a></li>
</ul></div>					<p>
						Digital Public Goods Alliance						-
						2023					</p>
				</div>

			</div>
			<div class="menu-social-container"><ul id="menu-social" class="menu"><li id="menu-item-897" class="twitter menu-item menu-item-type-custom menu-item-object-custom menu-item-897"><a target="_blank" rel="noopener" href="https://twitter.com/dpgalliance">Twitter</a></li>
<li id="menu-item-898" class="linkedin menu-item menu-item-type-custom menu-item-object-custom menu-item-898"><a target="_blank" rel="noopener" href="https://www.linkedin.com/company/dpgalliance">LinkedIn</a></li>
<li id="menu-item-911" class="github menu-item menu-item-type-custom menu-item-object-custom menu-item-911"><a target="_blank" rel="noopener" href="https://github.com/dpgalliance">Github</a></li>
</ul></div>		</div>
	</div>
</footer>
<script type='text/javascript' src='/wp-content/themes/dpga/js/libs.min.js?ver=1622233620' id='dpga-libs-js'></script>
<script type='text/javascript' src='/wp-content/themes/dpga/js/dpga.min.js?ver=1622233620' id='dpga-main-js'></script>
</body>

</html>